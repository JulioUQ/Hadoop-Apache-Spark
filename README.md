# ğŸ§  Hadoop & Apache Spark â€” Fundamentos de Big Data

Este repositorio contiene materiales teÃ³ricos y prÃ¡cticos del mÃ³dulo **Big Data Fundamentals**, centrado en el anÃ¡lisis de datos masivos con **Apache Hadoop** y **Apache Spark**.

## ğŸ“˜ DescripciÃ³n del mÃ³dulo

Las herramientas y tecnologÃ­as para el anÃ¡lisis de datos masivos (**Big Data**) estÃ¡n en constante evoluciÃ³n. El objetivo de este mÃ³dulo no es solo enumerarlas, sino **proporcionar las bases teÃ³ricas necesarias** para comprender este ecosistema y poder analizar de forma autÃ³noma las diferentes alternativas existentes.

A lo largo del mÃ³dulo se abordan tres grandes bloques:

1. **Modelos de programaciÃ³n en entornos de datos masivos**
    - IntroducciÃ³n al modelo **MapReduce** y su implementaciÃ³n en **Apache Hadoop**.
    - Ventajas, limitaciones y principales componentes del ecosistema Hadoop.
        
2. **Procesamiento distribuido con Apache Spark**
    - AnÃ¡lisis de su arquitectura, funcionamiento interno y diferencias respecto a MapReduce.
    - ProgramaciÃ³n con **RDDs** y **DataFrames** usando **PySpark**.
    - Aplicaciones prÃ¡cticas en el tratamiento de datos estructurados y no estructurados.
        
3. **Arquitecturas de procesamiento de datos masivos**
    - IntroducciÃ³n a la **arquitectura Lambda** como enfoque integral de procesamiento por lotes.
    - Breve revisiÃ³n de arquitecturas basadas en **GPU** y su aplicaciÃ³n en Big Data.


## ğŸ¯ Objetivos y competencias

### Del mÃ³dulo

- Comprender los **modelos de procesamiento distribuido** y sus aplicaciones.
- Conocer los principales **frameworks de Big Data**, como **Hadoop** y **Spark**.
- Familiarizarse con las **herramientas y servicios** para el procesamiento distribuido.
- Entender la **arquitectura Lambda** y su papel en el procesamiento por lotes.

### De la parte prÃ¡ctica

- Profundizar en el **paradigma Big Data**.
- Trabajar con datos en entornos **Apache Spark**.
- Aplicar el modelo **MapReduce** y su equivalencia en Spark.
- Usar **RDDs**, **PairRDDs** y la **API PySpark** para anÃ¡lisis y modelado de datos.

## Contenido del repositorio

```
HADOOP-APACHE-SPARK/  
â”‚  
â”œâ”€â”€ DataCamp Big Data Fundamentals with PySpark/  
â”‚   â”œâ”€â”€ Actividad_Batch_ES.ipynb  
â”‚   â”œâ”€â”€ Big Data Fundamentals with PySpark.md  
â”‚   â”œâ”€â”€ certificate.pdf  
â”‚   â”œâ”€â”€ PySpark_RDD_Cheat_Sheet.pdf  
â”‚   â””â”€â”€ README.md  
â”‚  
â”œâ”€â”€ PEC 2/  
â”‚   â”œâ”€â”€ Actividad_Batch_ES.ipynb
â”‚   â””â”€â”€ credentials.md  
â”‚  
â”œâ”€â”€ TeorÃ­a y videos/  
â”‚   â”œâ”€â”€ Gestores de recursos.pdf  
â”‚   â”œâ”€â”€ HadoopDefinitiveGuide.pdf  
â”‚   â”œâ”€â”€ Sistemas de procesamiento distribuido en ...pdf  
â”‚   â”œâ”€â”€ Tunneling_SSH.pdf  
â”‚   â”œâ”€â”€ Uso de dataframes con Apache Spark.mp4  
â”‚   â””â”€â”€ Uso de RDDs con Apache Spark.mp4  
â”‚  
â””â”€â”€ README.md  
```  

## ğŸ§  Recursos de referencia

ğŸ“„ [RDD Programming Guide](https://archive.apache.org/dist/spark/docs/2.4.0/rdd-programming-guide.html)  
ğŸ“„ [Spark SQL, DataFrames and Datasets Guide](https://archive.apache.org/dist/spark/docs/2.4.0/sql-getting-started.html)

## ğŸ… CertificaciÃ³n

Este repositorio incluye el certificado de finalizaciÃ³n del curso **Big Data Fundamentals with PySpark** realizado en **DataCamp**, enfocado en:

- Transformaciones y acciones con **RDDs**
- Consultas con **SparkSQL**
- Modelado con **MLlib**
- ConstrucciÃ³n de un recomendador de pelÃ­culas y un filtro de spam

## ğŸ’¬ Autor

**Julio Ãšbeda Quesada**  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/tu-perfil/)  
ğŸ“§ Contacto: julioubedaquesada@gmail.com
